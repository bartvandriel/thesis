{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TRAINING.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"dGn8QMbfTWec","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"50dc2318-a5aa-4a29-8582-17cc269396c1","executionInfo":{"status":"ok","timestamp":1551084441877,"user_tz":-60,"elapsed":1898,"user":{"displayName":"Bart van Driel","photoUrl":"","userId":"17232338587989471094"}}},"cell_type":"code","source":["import sys\n","import random\n","random.seed(42)\n","import numpy as np\n","np.random.seed(42)\n","from keras import backend as K\n","from tensorflow import set_random_seed\n","set_random_seed(42)\n","\n","\n","from keras.optimizers import Adam, SGD\n","from keras.callbacks import Callback, CSVLogger, ModelCheckpoint\n","from tqdm import tqdm\n","from sklearn.utils import class_weight"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"pl_JlbI7jzxg","colab_type":"code","colab":{}},"cell_type":"code","source":["from imblearn.keras import balanced_batch_generator\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2AfcDte_JJdu","colab_type":"text"},"cell_type":"markdown","source":["**VGG**"]},{"metadata":{"id":"HtWQrRnzJAu4","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","\n","\n","def preprocess_input_vgg(x):\n","      \"\"\"Wrapper around keras.applications.vgg16.preprocess_input()\n","      to make it compatible for use with keras.preprocessing.image.ImageDataGenerator's\n","      `preprocessing_function` argument.\n","\n","      Parameters\n","      ----------\n","      x : a numpy 3darray (a single image to be preprocessed)\n","\n","      Note we cannot pass keras.applications.vgg16.preprocess_input()\n","      directly to to keras.preprocessing.image.ImageDataGenerator's\n","      `preprocessing_function` argument because the former expects a\n","      4D tensor whereas the latter expects a 3D tensor. Hence the\n","      existence of this wrapper.\n","\n","      Returns a numpy 3darray (the preprocessed image).\n","\n","      \"\"\"\n","      from keras.applications.vgg16 import preprocess_input\n","      X = np.expand_dims(x, axis=0)\n","      X = preprocess_input(X)\n","      return X[0]\n","\n","\n","def get_VGG_data_generator(file_num, file_name, fraction):\n","  print('VGG DATA GENERATOR')\n","\n","\n","  import os\n","  import zipfile\n","#   local_zip = 'gdrive/My Drive/Colab Notebooks/UC_Merced/' + file_name\n","#   local_zip = 'gdrive/My Drive/Colab Notebooks/Sint_Maarten/' + 'shape/' + str(fraction) + '/'+ file_name\n","  local_zip = 'gdrive/My Drive/Colab Notebooks/Sint_Maarten/' + 'material/' + str(fraction) + '/'+ file_name\n","\n","\n","  print(local_zip)\n","  zip_ref = zipfile.ZipFile(local_zip, 'r')\n","  zip_ref.extractall('/tmp')\n","  zip_ref.close()\n","\n","  base_dir = '/tmp/' + file_name.split(\".\")[0]\n","  # base_dir = '/tmp/UC_Merced_filtered_45'\n","\n","  print(base_dir)\n","\n","  train_dir = os.path.join(base_dir, 'train')\n","  validation_dir = os.path.join(base_dir, 'validation')\n","  test_dir = os.path.join(base_dir, 'test')\n","\n","\n","  # Adding rescale, rotation_range, width_shift_range, height_shift_range,\n","  # shear_range, zoom_range, and horizontal flip to our ImageDataGenerator\n","  train_datagen = ImageDataGenerator(\n","      preprocessing_function=preprocess_input_vgg,\n","      rotation_range=180,\n","      horizontal_flip=True,\n","      vertical_flip=True\n","  )\n","\n","  # Note that the validation and test data should not be augmented!\n","  val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg)\n","  test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg)\n","\n","  # Flow training images in batches of 16 using train_datagen generator\n","  train_generator = train_datagen.flow_from_directory(\n","          train_dir,  # This is the source directory for training images\n","          target_size=(224, 224),  # All images will be resized to 150x150\n","          batch_size=16,\n","          # Since we use binary_crossentropy loss, we need binary labels\n","          class_mode='sparse', \n","          shuffle=True)\n","\n","  # Flow validation images in batches of 16 using test_datagen generator\n","  validation_generator = val_datagen.flow_from_directory(\n","          validation_dir,\n","          target_size=(224, 224),\n","          batch_size=16,\n","          class_mode='sparse')\n","\n","  # Flow test images in batches of 16 using test_datagen generator\n","  test_generator = test_datagen.flow_from_directory(\n","          test_dir,\n","          target_size=(224, 224),\n","          batch_size=100,\n","          class_mode='sparse')\n","  \n","  return train_generator, validation_generator, test_generator\n","\n","\n","\n","def get_VGG(n_classes):\n","  print('VGG MODEL')\n","  \n","  from keras.applications.vgg16 import  VGG16\n","  from keras.models import Model\n","  from keras.layers import Dense, GlobalAveragePooling2D, Input, Flatten\n","  from keras.layers import Dropout, BatchNormalization\n","\n","  \n","  base_model  = VGG16(weights='imagenet', include_top=False, input_shape=(224,224, 3))\n","#   base_model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)\n","\n","\n","  for layer in base_model.layers[:-9]:\n","      layer.trainable = False\n","\n","\n","  x = base_model.output\n","  x = Flatten()(x)\n","\n","  x = Dense(4096, activation='relu', name='fc1')(x)\n","  x = Dense(4096, activation='relu', name='fc2')(x)\n","\n","  # and a logistic layer -- let's say we have 200 classes\n","  predictions = Dense(n_classes, activation='softmax', name='predictions')(x)\n","\n","  # this is the model we will train\n","  model = Model(inputs=base_model.input, outputs=predictions)\n","  \n","#   for layer in model.layers:\n","#     print(layer.name, layer.trainable)\n","\n","\n","\n","  return model "],"execution_count":0,"outputs":[]},{"metadata":{"id":"oGyyck6BMKeB","colab_type":"text"},"cell_type":"markdown","source":["**Xception**"]},{"metadata":{"id":"NFnp2F7tJOKz","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","\n","def get_Xception_data_generator(file_num, file_name):\n","  from keras.applications.xception import preprocess_input\n","  \n","  \n","  print('Xception DATA GENERATOR')\n","    \n","  import os\n","  import zipfile\n","#   local_zip = 'gdrive/My Drive/Colab Notebooks/UC_Merced/' + file_name\n","#   local_zip = 'gdrive/My Drive/Colab Notebooks/Sint_Maarten/shape/' + file_name\n","  local_zip = 'gdrive/My Drive/Colab Notebooks/Sint_Maarten/material/' + file_name\n","\n","\n","  print(local_zip)\n","  zip_ref = zipfile.ZipFile(local_zip, 'r')\n","  zip_ref.extractall('/tmp')\n","  zip_ref.close()\n","\n","  base_dir = '/tmp/' + file_name.split(\".\")[0]\n","  # base_dir = '/tmp/UC_Merced_filtered_45'\n","\n","  print(base_dir)\n","\n","  train_dir = os.path.join(base_dir, 'train')\n","  validation_dir = os.path.join(base_dir, 'validation')\n","  test_dir = os.path.join(base_dir, 'test')\n","\n","\n","  # Adding rescale, rotation_range, width_shift_range, height_shift_range,\n","  # shear_range, zoom_range, and horizontal flip to our ImageDataGenerator\n","  train_datagen = ImageDataGenerator(\n","      preprocessing_function=preprocess_input,\n","      rotation_range=180,\n","      horizontal_flip=True,\n","      vertical_flip=True)\n","\n","  # Note that the validation and test data should not be augmented!\n","  val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","  test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","  # Flow training images in batches of 16 using train_datagen generator\n","  train_generator = train_datagen.flow_from_directory(\n","          train_dir,  # This is the source directory for training images\n","          target_size=(299, 299),  # All images will be resized to 150x150\n","          batch_size=16,\n","          # Since we use binary_crossentropy loss, we need binary labels\n","          class_mode='sparse', \n","          shuffle=True)\n","\n","  # Flow validation images in batches of 16 using test_datagen generator\n","  validation_generator = val_datagen.flow_from_directory(\n","          validation_dir,\n","          target_size=(299, 299),\n","          batch_size=16,\n","          class_mode='sparse')\n","\n","  # Flow test images in batches of 16 using test_datagen generator\n","  test_generator = test_datagen.flow_from_directory(\n","          test_dir,\n","          target_size=(299, 299),\n","          batch_size=100,\n","          class_mode='sparse')\n","  \n","  return train_generator, validation_generator, test_generator\n","\n","\n","\n","\n","def get_Xception(n_classes):\n","  \n","  print('Xception MODEL')\n","  from keras.applications.xception import Xception\n","\n","  from keras.models import Model\n","  from keras.layers import Dense, GlobalAveragePooling2D, Input, Flatten\n","  \n","\n","  # create the base pre-trained model\n","  base_model = Xception(weights='imagenet', include_top=False, input_shape=(299,299, 3))\n","\n","  for layer in base_model.layers[:95]:\n","    layer.trainable = False\n","\n","    # add a global spatial average pooling layer\n","  x = base_model.output\n","  x = GlobalAveragePooling2D()(x)\n","  predictions = Dense(n_classes, activation='softmax')(x)\n","\n","\n","  # this is the model we will train\n","  model = Model(inputs=base_model.input, outputs=predictions)\n","\n","\n","  return model \n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UBeP9-4HJk39","colab_type":"text"},"cell_type":"markdown","source":["**Inception**"]},{"metadata":{"id":"zYfNYglIMJ9p","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","\n","\n","def get_Inception_data_generator(file_num, file_name):\n","  from keras.applications.inception_v3 import preprocess_input\n","\n","  \n","  print('INCEPTION DATA GENERATOR')\n","    \n","  import os\n","  import zipfile\n","  \n","#   local_zip = 'gdrive/My Drive/Colab Notebooks/UC_Merced/' + file_name\n","#   local_zip = 'gdrive/My Drive/Colab Notebooks/Sint_Maarten/shape/' + file_name\n","  local_zip = 'gdrive/My Drive/Colab Notebooks/Sint_Maarten/material/' + file_name\n","\n","\n","  print(local_zip)\n","  zip_ref = zipfile.ZipFile(local_zip, 'r')\n","  zip_ref.extractall('/tmp')\n","  zip_ref.close()\n","\n","  base_dir = '/tmp/' + file_name.split(\".\")[0]\n","  # base_dir = '/tmp/UC_Merced_filtered_45'\n","\n","  print(base_dir)\n","\n","  train_dir = os.path.join(base_dir, 'train')\n","  validation_dir = os.path.join(base_dir, 'validation')\n","  test_dir = os.path.join(base_dir, 'test')\n","\n","\n","  # Adding rescale, rotation_range, width_shift_range, height_shift_range,\n","  # shear_range, zoom_range, and horizontal flip to our ImageDataGenerator\n","  train_datagen = ImageDataGenerator(\n","      preprocessing_function=preprocess_input,\n","      rotation_range=180,\n","      horizontal_flip=True,\n","      vertical_flip=True)\n","\n","  # Note that the validation and test data should not be augmented!\n","  val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","  test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","  # Flow training images in batches of 16 using train_datagen generator\n","  train_generator = train_datagen.flow_from_directory(\n","          train_dir,  # This is the source directory for training images\n","          target_size=(299, 299),  # All images will be resized to 150x150\n","          batch_size=32,\n","          # Since we use binary_crossentropy loss, we need binary labels\n","          class_mode='sparse', \n","          shuffle=True)\n","\n","  # Flow validation images in batches of 16 using test_datagen generator\n","  validation_generator = val_datagen.flow_from_directory(\n","          validation_dir,\n","          target_size=(299, 299),\n","          batch_size=32,\n","          class_mode='sparse')\n","\n","  # Flow test images in batches of 16 using test_datagen generator\n","  test_generator = test_datagen.flow_from_directory(\n","          test_dir,\n","          target_size=(299, 299),\n","          batch_size=100,\n","          class_mode='sparse')\n","  \n","  return train_generator, validation_generator, test_generator\n","\n","\n","\n","\n","def get_Inception(n_classes):\n","  \n","  print('INCEPTION MODEL')\n","  \n","  from keras.applications.vgg16 import  VGG16\n","  from keras.applications.inception_v3 import InceptionV3\n","  from keras.models import Model\n","  from keras.layers import Dense, GlobalAveragePooling2D, Input, Flatten\n","  \n","\n","\n","  # create the base pre-trained model\n","  base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299,299, 3))\n","  \n","  for layer in base_model.layers[:249]:\n","    layer.trainable = False\n","\n","  # add a global spatial average pooling layer\n","  x = base_model.output\n","  x = GlobalAveragePooling2D()(x)\n","  # let's add a fully-connected layer\n","  x = Dense(1024, activation='relu')(x)\n","  # and a logistic layer -- let's say we have 200 classes\n","  predictions = Dense(n_classes, activation='softmax')(x)\n","\n","  # this is the model we will train\n","  model = Model(inputs=base_model.input, outputs=predictions)\n","\n","\n","  return model \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YiTVhrvrPuQx","colab_type":"text"},"cell_type":"markdown","source":["**FUNCTION**"]},{"metadata":{"id":"-Sc6yqWaH7Ga","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","def set_data_generators(file_num, network, file_name, fraction):\n","  \n","  if network == 'VGG':\n","    train_generator, validation_generator, test_generator = get_VGG_data_generator(file_num, file_name, fraction)\n","    \n","  elif network == 'Inception':\n","    train_generator, validation_generator, test_generator = get_Inception_data_generator(file_num, file_name)\n","    \n","  elif network == 'Xception':\n","    train_generator, validation_generator, test_generator = get_Xception_data_generator(file_num, file_name)\n","  \n","    \n","  return train_generator, validation_generator, test_generator\n","\n","\n","\n","def get_model(network, n_classes):\n","  \n","  if network == 'VGG':\n","    model = get_VGG(n_classes)\n","          \n","  elif network == 'Inception':\n","    model = get_Inception(n_classes)\n","    \n","  elif network == 'Xception':\n","    model = get_Xception(n_classes)\n","    \n","  return model\n","    \n","              "],"execution_count":0,"outputs":[]},{"metadata":{"id":"tOLPKqrvPAIs","colab_type":"text"},"cell_type":"markdown","source":["**Loop**"]},{"metadata":{"id":"bNtvovw8pn3v","colab_type":"code","colab":{}},"cell_type":"code","source":["def loop(file_num, network, fraction):\n","\n","  #Filename\n","#   file_name = 'UC_Merced_filtered_'+ str(file_num) +'.zip'\n","#   file_name = 'roof_shape_'+ str(file_num*10) +'_0_9' + '.zip'\n","  file_name = 'roof_material_'+ str(file_num*10) +'_0_9' + '.zip'\n","\n","\n","  #generators\n","  train_generator, validation_generator, test_generator = set_data_generators(file_num, network, file_name, fraction)\n","\n","  model = get_model(network,  train_generator.num_classes)\n","  \n","  #Class weights\n","  class_weights = class_weight.compute_class_weight('balanced',\n","                                                   np.unique(train_generator.classes),\n","                                                   train_generator.classes)\n","  \n","#   print(class_weights)\n","\n","  #file paths\n","  PATH = '/content/gdrive/My Drive/Colab Notebooks/Sint_Maarten/pickles/models/' + network + '/' + str(fraction) + '/'\n","  model_file_path = PATH + 'trained_models/' + str(train_generator.num_classes) + '_' + file_name.split(\".\")[0]\n","  csv_file_path = PATH + 'logs/' + str(train_generator.num_classes) + '_' + file_name.split(\".\")[0] + '.csv'\n","  \n","  \n","  #Callbacks\n","  callbacks = list()\n","  callbacks.append(CSVLogger(csv_file_path, separator=',', append=False))\n","#   callbacks.append(ModelCheckpoint(model_file_path, monitor='val_acc', verbose=1, save_best_only=True,\n","#                                  save_weights_only=False, mode='auto', period=3))\n","  \n","  if network == 'VGG':\n","    opt = SGD(lr=0.001)\n","    epoch = 15\n","  elif network == 'Inception':\n","    opt = SGD(lr=0.01) \n","    epoch = 15\n","  elif network == 'Xception':\n","    opt = SGD(lr=0.01)\n","    epoch = 30\n","  \n","  model.compile(loss='sparse_categorical_crossentropy',\n","                optimizer=opt,\n","                metrics=['acc'])\n","\n","  # Fit Model\n","  model_info = model.fit_generator(train_generator,\n","                                   epochs=epoch,\n","                                   steps_per_epoch=train_generator.samples/train_generator.batch_size,\n","                                   verbose=1,\n","                                   validation_data=validation_generator,\n","                                   validation_steps=validation_generator.samples/validation_generator.batch_size,\n","                                   callbacks=callbacks,\n","                                   class_weight=class_weights\n","                                   )\n","  \n","  \n","  #Callbacks\n","  callbacks = list()\n","  callbacks.append(CSVLogger(csv_file_path, separator=',', append=True))\n","  callbacks.append(ModelCheckpoint(model_file_path, monitor='val_acc', verbose=1, save_best_only=True,\n","                                 save_weights_only=False, mode='auto', period=1))\n","    \n","    \n","  #optimizers\n","  \n","  if network == 'VGG':\n","    opt = SGD(lr=0.001)\n","    epoch = 45\n","  elif network == 'Inception':\n","    opt = SGD(lr=0.001)  \n","    epoch = 45\n","  elif network == 'Xception':\n","    opt = SGD(lr=0.001)\n","    epoch = 70\n","\n","   \n","  model.compile(loss='sparse_categorical_crossentropy',\n","                optimizer=opt,\n","                metrics=['acc'])\n","\n","  # Fit Model\n","  model_info = model.fit_generator(train_generator,\n","                                   epochs=epoch,\n","                                   steps_per_epoch=train_generator.samples/train_generator.batch_size,\n","                                   verbose=1,\n","                                   validation_data=validation_generator,\n","                                   validation_steps=validation_generator.samples/validation_generator.batch_size,\n","                                   callbacks=callbacks,\n","                                   class_weight=class_weights\n","                                   )\n","  \n","  \n","  \n","\n","  train_generator.reset()\n","  validation_generator.reset()\n","  model = []\n","\n","  K.clear_session()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GtBnfvnv2vYO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"0082323d-66c1-497a-e97d-24364e6e672b","executionInfo":{"status":"ok","timestamp":1551084458675,"user_tz":-60,"elapsed":18598,"user":{"displayName":"Bart van Driel","photoUrl":"","userId":"17232338587989471094"}}},"cell_type":"code","source":["from google.colab import drive    \n","drive.mount('/content/gdrive')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"aFYQrsu3R53Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":423},"outputId":"98cc1c6d-d702-45b3-9666-bdbba41f0792"},"cell_type":"code","source":["for network in ['VGG']:\n","  for fraction in ['10']:\n","\n","    for file_num in [i*1 for i in range(1,11)]:\n","\n","      loop(file_num, network, fraction)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["VGG DATA GENERATOR\n","gdrive/My Drive/Colab Notebooks/Sint_Maarten/material/10/roof_material_10_0_9.zip\n","/tmp/roof_material_10_0_9\n","Found 814 images belonging to 3 classes.\n","Found 351 images belonging to 3 classes.\n","Found 10496 images belonging to 3 classes.\n","VGG MODEL\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 2s 0us/step\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/15\n","51/50 [==============================] - 30s 580ms/step - loss: 1.4849 - acc: 0.5432 - val_loss: 1.0213 - val_acc: 0.5071\n","Epoch 2/15\n","51/50 [==============================] - 18s 352ms/step - loss: 0.9656 - acc: 0.5527 - val_loss: 1.0000 - val_acc: 0.5385\n","Epoch 3/15\n","51/50 [==============================] - 18s 353ms/step - loss: 0.9175 - acc: 0.5837 - val_loss: 0.9551 - val_acc: 0.5869\n","Epoch 4/15\n","12/50 [======>.......................] - ETA: 11s - loss: 0.8620 - acc: 0.6562"],"name":"stdout"}]}]}